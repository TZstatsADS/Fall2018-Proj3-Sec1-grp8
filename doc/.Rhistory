begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(dat_train$label[1,,1]~dat_train$feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
dat_train$label[1,,1]
#install.packages("neuralnet")
run.nnt=T
train_nn = function(dat_train){
library("neuralnet")
begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(dat_train$label[1,,1]~dat_train$feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
#install.packages("neuralnet")
run.nnt=T
train_nn = function(dat_train){
library("neuralnet")
begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(label[1,,1]~feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
#install.packages("neuralnet")
run.nnt=T
train_nn = function(dat_train){
library("neuralnet")
begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(dat_train$label[1,,1]~dat_train$feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
rm(list=ls())
#install.packages("neuralnet")
run.nnt=T
train_nn = function(dat_train){
library("neuralnet")
begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(dat_train$label[1,,1]~dat_train$feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
set.seed(2018)
# setwd("Fall2018-Proj3-Sec1-grp8/")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
#
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
dat_train
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
set.seed(2018)
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
#
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
dat_train
source("../lib/feature.R")
#
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
source("../lib/feature.R")
#
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
feat_train
source("../lib/train.R")
source("../lib/test.R")
#install.packages("neuralnet")
run.nnt=T
train_nn = function(dat_train){
library("neuralnet")
begin = Sys.time()
#for (i in 1:12){
#  n <- names(dat_train)
#  c1 <- (i-1) %% 4 + 1
#  c2 <- (i-c1) %/% 4 + 1
#  model <- neuralnet(dat_train$label[, c1, c2]~dat_train$feature[, , c2],data=dat_train,hidden=1,linear.output = T)
#}
model <- neuralnet(dat_train$label[1,,1]~dat_train$feature[1,,1],data=dat_train,hidden=1,linear.output = T)
end= Sys.time()
time = end - begin #Total Running Time
return(list(fit = model, time = time))
}
if(run.nnt){
nnt_train <- train_nn(dat_train)
cat("Time for testing neural network model=", nnt_train$time, "s \n")
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
#
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train$feature, dat_train$label, model_values[k,], K)
}
save(err_cv, file="../output/err_cv.RData")
}
tm_train=NA
load(file="../output/err_cv.RData"))
load(file="../output/err_cv.RData")
tm_train=NA
tm_train <- system.time(fit_train <- train(feat_train, label_train, par_best))
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
model_values
which.min(err_cv[,1])
model_best <- model_values[which.min(err_cv[,1]),]
model_best
model_best=model_values[1,]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1]),]
}
tm_train=NA
tm_train <- system.time(fit_train <- train(feat_train, label_train, model_best))
save(fit_train, file="../output/fit_train.RData")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train$feature, dat_train$label, model_values[k,], K)
}
save(err_cv, file="../output/err_cv.RData")
}
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train$feature, dat_train$label, model_values[k,], K)
}
save(err_cv, file="../output/err_cv.RData")
}
View(err_cv)
model_values
load(file="../output/err_cv.RData")
View(err_cv)
test_dir <- "../data/test_set/"
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
LR_dir<- test_LR_dir
HR_dir<- test_HR_dir
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", 1), ".jpg"))
getwd()
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", 1), ".jpg"))
imgLR <- as.array(imgLR@.Data)
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", 1), ".jpg")
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
rows=dim(imgLR)[1]
cols=dim(imgLR)[2]
profvis({
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for (d in 1:3) {
padded<- matrix(0,nrow = rows+2,ncol = cols+2)
padded[2:(rows+1),2:(cols+1)]<- imgLR[,,d]
count<- 0
for (k in 2:(rows+1)) {
for (j in 2:(cols+1)) {
neighbor8<- c(padded[k-1,j-1],padded[k,j-1],padded[k+1,j-1],padded[k-1,j],padded[k+1,j],padded[k-1,j+1],padded[k,j+1],padded[k+1,j+1])
- (c(padded[(k-1):(k+1),(j-1):(j+1)])[-5] !=0) * padded[k,j]
count <- count+1
featMat[count,,d]<- neighbor8
}
}
}
### step 2. apply the modelList over featMat
predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
# predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
### step 3. recover high-resolution from predMat and save in HR_dir
predArray<- array(predMAT,c(rows*2,cols*2,3))
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
predicted_image<- Image(predArray, colormode = Color)
photo_name<- paste0("img","_",sprintf("%04d",i),".jpg")
writeImage(predicted_image,photo_name)
})
library(profvis)
profvis({
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for (d in 1:3) {
padded<- matrix(0,nrow = rows+2,ncol = cols+2)
padded[2:(rows+1),2:(cols+1)]<- imgLR[,,d]
count<- 0
for (k in 2:(rows+1)) {
for (j in 2:(cols+1)) {
neighbor8<- c(padded[k-1,j-1],padded[k,j-1],padded[k+1,j-1],padded[k-1,j],padded[k+1,j],padded[k-1,j+1],padded[k,j+1],padded[k+1,j+1])
- (c(padded[(k-1):(k+1),(j-1):(j+1)])[-5] !=0) * padded[k,j]
count <- count+1
featMat[count,,d]<- neighbor8
}
}
}
### step 2. apply the modelList over featMat
predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
# predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
### step 3. recover high-resolution from predMat and save in HR_dir
predArray<- array(predMAT,c(rows*2,cols*2,3))
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
predicted_image<- Image(predArray, colormode = Color)
photo_name<- paste0("img","_",sprintf("%04d",i),".jpg")
writeImage(predicted_image,photo_name)
})
load(file="../output/fit_train.RData")
modelList <- fit-train
modelList <- fit_train
profvis({
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for (d in 1:3) {
padded<- matrix(0,nrow = rows+2,ncol = cols+2)
padded[2:(rows+1),2:(cols+1)]<- imgLR[,,d]
count<- 0
for (k in 2:(rows+1)) {
for (j in 2:(cols+1)) {
neighbor8<- c(padded[k-1,j-1],padded[k,j-1],padded[k+1,j-1],padded[k-1,j],padded[k+1,j],padded[k-1,j+1],padded[k,j+1],padded[k+1,j+1])
- (c(padded[(k-1):(k+1),(j-1):(j+1)])[-5] !=0) * padded[k,j]
count <- count+1
featMat[count,,d]<- neighbor8
}
}
}
### step 2. apply the modelList over featMat
predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
# predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
### step 3. recover high-resolution from predMat and save in HR_dir
predArray<- array(predMAT,c(rows*2,cols*2,3))
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
predicted_image<- Image(predArray, colormode = Color)
photo_name<- paste0("img","_",sprintf("%04d",i),".jpg")
writeImage(predicted_image,photo_name)
})
display(predicted_image)
profvis({
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for (d in 1:3) {
padded<- matrix(0,nrow = rows+2,ncol = cols+2)
padded[2:(rows+1),2:(cols+1)]<- imgLR[,,d]
count<- 0
for (k in 2:(rows+1)) {
for (j in 2:(cols+1)) {
neighbor8 <- c(padded[(k-1):(k+1),(j-1):(j+1)])
neighbor8 <- neighbor8[-5] - (neighbor8[-5] != 0) * padded[k,j]
count <- count+1
featMat[count,,d]<- neighbor8
}
}
}
### step 2. apply the modelList over featMat
predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
# predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
### step 3. recover high-resolution from predMat and save in HR_dir
predArray<- array(predMAT,c(rows*2,cols*2,3))
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
predicted_image<- Image(predArray, colormode = Color)
photo_name<- paste0("img","_",sprintf("%04d",i),".jpg")
writeImage(predicted_image,photo_name)
})
display(predicted_image)
