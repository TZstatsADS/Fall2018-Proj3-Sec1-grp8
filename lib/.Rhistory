geom_point(data = centroids[centroids$propRetired < 0.3,], aes(x = x, y = y, colour = propRetired)) +
# geom_point(data = centroids[centroids$propRetired > 0.3,], aes(x = x, y = y), colour = "white") +
# geom_text(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)), colour = "white") +
geom_label_repel(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)),
box.padding   = 1,
point.padding = 0.5,
segment.color = 'black', alpha=I(0.6) ) +
scale_colour_gradient(low = "yellow", high = "red") +
# scale_colour_gradient(low = "green", high = "blue") +
theme_void()
ggplot(shapeDf) +
geom_polygon(aes(long, lat, group=group, fill=`prop owner occupied`)) +
coord_equal() +
geom_point(data = centroids, aes(x = x, y = y, colour = propWhite)) +
scale_colour_gradient(low = "yellow", high = "red") +
theme_void()
crimes <- read.csv("crimes.csv")
crimes <- crimes %>% subset(LAW_CAT_CD == "FELONY" & !is.na(Latitude) & !is.na(Longitude))
# coordinates(crimes) <- ~ Latitude + Longitude
xy <- cbind(crimes$Longitude, crimes$Latitude)
spdf <- SpatialPointsDataFrame(coords = xy, data = crimes,
proj4string = CRS("+init=epsg:4269 +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"))
shapeProj <- spTransform(shape, "+init=epsg:4269")
ID <- over(spdf, as(shapeProj,"SpatialPolygons"))
spdf@data <- cbind(spdf@data, ID)
a <- spdf@data %>% group_by(ID) %>% dplyr::summarize(crimes = n())
shapeProj@data <- merge(shapeProj@data, a, by = "row.names")
shapeProj@data[nrow(shapeProj@data)+1:9,] <- NA
shapeProj@data$id = rownames(shapeProj@data)
crimePoints = fortify(shapeProj, region="id")
crimesDf = join(crimesPoints, shapeProj@data, by="id")
ggplot(crimesDf) +
geom_polygon(aes(long,lat,group=group, fill = crimes)) +
theme_void()
crimesRobbery <- crimes[crimes$OFNS_DESC == "ROBBERY",]
crimesWeapons <- crimes[crimes$OFNS_DESC == "DANGEROUS WEAPONS",]
crimesDrugs <- crimes[crimes$OFNS_DESC == "DANGEROUS DRUGS",]
ggplot(crimesDf) +
geom_polygon(aes(long,lat,group=group, fill = crimes)) +
coord_equal() +
stat_ellipse(data = crimesRobbery, aes(x = Longitude, y = Latitude), level=0.5, color = "red") +
geom_point(data = crimesRobbery, aes(x = mean(Longitude), y = mean(Latitude)), color = "red", size = 0.5) +
stat_ellipse(data = crimesWeapons, aes(x = Longitude, y = Latitude), level=0.5, color = "orange") +
geom_point(data = crimesWeapons, aes(x = mean(Longitude), y = mean(Latitude)), color = "orange", size = 0.5) +
stat_ellipse(data = crimesDrugs, aes(x = Longitude, y = Latitude), level=0.5, color = "green") +
geom_point(data = crimesDrugs, aes(x = mean(Longitude), y = mean(Latitude)), color = "green", size = 0.5) +
theme_void()
knitr::opts_chunk$set(echo = F, message = F, warning = F)
packages <- c("rgdal", "foreign", "gdata", "ggmap", "ggplot2",
"plyr", "rgeos", "sf", "ggrepel", "dplyr", "sp", "aspace",
"spdep")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = T)) install.packages(x)
if (! (x %in% (.packages() )))  library(x, character.only = T)
})
load("NY.RData")
shape@data$id = rownames(shape@data)
shapePoints = fortify(shape, region="id")
shapeDf = join(shapePoints, shape@data, by="id")
ggplot(shapeDf) +
aes(long,lat,group=group,fill=`prop owner occupied`) +
geom_polygon() +
coord_equal() + theme_void()
shape@data$id = rownames(shape@data)
shapePoints = fortify(shape, region="id")
shapeDf = join(shapePoints, shape@data, by="id")
propRetired <- (shape@data$` 85 years and over` + shape@data$` 80 to 84 years` +
shape@data$` 75 to 79 years` + shape@data$` 70 to 74 years` +
shape@data$` 65 to 69 years`) / shape@data$`Total:`
propWhite <- shape@data$`  White` / shape@data$`Total:`
centroids = as.data.frame(gCentroid(shape,byid=TRUE))
centroids <- cbind(centroids,propRetired, propWhite)
centroids <- centroids[complete.cases(centroids),]
ggplot(shapeDf) +
geom_polygon(aes(long, lat, group=group, fill=`prop owner occupied`)) +
coord_equal() +
geom_point(data = centroids[centroids$propRetired < 0.3,], aes(x = x, y = y, colour = propRetired)) +
# geom_point(data = centroids[centroids$propRetired > 0.3,], aes(x = x, y = y), colour = "white") +
# geom_text(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)), colour = "white") +
geom_label_repel(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)),
box.padding   = 1,
point.padding = 0.5,
segment.color = 'black', alpha=I(0.6) ) +
scale_colour_gradient(low = "yellow", high = "red") +
# scale_colour_gradient(low = "green", high = "blue") +
theme_void()
ggplot(shapeDf) +
geom_polygon(aes(long, lat, group=group, fill=`prop owner occupied`)) +
coord_equal() +
geom_point(data = centroids, aes(x = x, y = y, colour = propWhite)) +
scale_colour_gradient(low = "yellow", high = "red") +
theme_void()
crimes <- read.csv("crimes.csv")
crimes <- crimes %>% subset(LAW_CAT_CD == "FELONY" & !is.na(Latitude) & !is.na(Longitude))
# coordinates(crimes) <- ~ Latitude + Longitude
xy <- cbind(crimes$Longitude, crimes$Latitude)
spdf <- SpatialPointsDataFrame(coords = xy, data = crimes,
proj4string = CRS("+init=epsg:4269 +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"))
shapeProj <- spTransform(shape, "+init=epsg:4269")
ID <- over(spdf, as(shapeProj,"SpatialPolygons"))
spdf@data <- cbind(spdf@data, ID)
a <- spdf@data %>% group_by(ID) %>% dplyr::summarize(crimes = n())
shapeProj@data <- merge(shapeProj@data, a, by = "row.names")
shapeProj@data[nrow(shapeProj@data)+1:9,] <- NA
knitr::opts_chunk$set(echo = F, message = F, warning = F)
packages <- c("rgdal", "foreign", "gdata", "ggmap", "ggplot2",
"plyr", "rgeos", "sf", "ggrepel", "dplyr", "sp", "aspace",
"spdep")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = T)) install.packages(x)
if (! (x %in% (.packages() )))  library(x, character.only = T)
})
load("NY.RData")
shape@data$id = rownames(shape@data)
shapePoints = fortify(shape, region="id")
shapeDf = join(shapePoints, shape@data, by="id")
ggplot(shapeDf) +
aes(long,lat,group=group,fill=`prop owner occupied`) +
geom_polygon() +
coord_equal() + theme_void()
shape@data$id = rownames(shape@data)
shapePoints = fortify(shape, region="id")
shapeDf = join(shapePoints, shape@data, by="id")
propRetired <- (shape@data$` 85 years and over` + shape@data$` 80 to 84 years` +
shape@data$` 75 to 79 years` + shape@data$` 70 to 74 years` +
shape@data$` 65 to 69 years`) / shape@data$`Total:`
propWhite <- shape@data$`  White` / shape@data$`Total:`
centroids = as.data.frame(gCentroid(shape,byid=TRUE))
centroids <- cbind(centroids,propRetired, propWhite)
centroids <- centroids[complete.cases(centroids),]
ggplot(shapeDf) +
geom_polygon(aes(long, lat, group=group, fill=`prop owner occupied`)) +
coord_equal() +
geom_point(data = centroids[centroids$propRetired < 0.3,], aes(x = x, y = y, colour = propRetired)) +
# geom_point(data = centroids[centroids$propRetired > 0.3,], aes(x = x, y = y), colour = "white") +
# geom_text(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)), colour = "white") +
geom_label_repel(data=centroids[centroids$propRetired > 0.3,], aes(x, y, label = round(propRetired, 2)),
box.padding   = 1,
point.padding = 0.5,
segment.color = 'black', alpha=I(0.6) ) +
scale_colour_gradient(low = "yellow", high = "red") +
# scale_colour_gradient(low = "green", high = "blue") +
theme_void()
ggplot(shapeDf) +
geom_polygon(aes(long, lat, group=group, fill=`prop owner occupied`)) +
coord_equal() +
geom_point(data = centroids, aes(x = x, y = y, colour = propWhite)) +
scale_colour_gradient(low = "yellow", high = "red") +
theme_void()
crimes <- read.csv("crimes.csv")
crimes <- crimes %>% subset(LAW_CAT_CD == "FELONY" & !is.na(Latitude) & !is.na(Longitude))
# coordinates(crimes) <- ~ Latitude + Longitude
xy <- cbind(crimes$Longitude, crimes$Latitude)
spdf <- SpatialPointsDataFrame(coords = xy, data = crimes,
proj4string = CRS("+init=epsg:4269 +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"))
shapeProj <- spTransform(shape, "+init=epsg:4269")
ID <- over(spdf, as(shapeProj,"SpatialPolygons"))
spdf@data <- cbind(spdf@data, ID)
a <- spdf@data %>% group_by(ID) %>% dplyr::summarize(crimes = n())
shapeProj@data <- merge(shapeProj@data, a, by = "row.names")
shapeProj@data[nrow(shapeProj@data)+1:9,] <- NA
knit_with_parameters('~/Google_Drive/docs/UNIS/KU Leuven/Exchange/columbia/Courses/Spatial Statistics/HWs/Midterm/MidtermGabriel.Rmd')
shapeProj@data$id = rownames(shapeProj@data)
crimePoints = fortify(shapeProj, region="id")
crimePoints = fortify(shapeProj, region="id")
crimesDf = join(crimesPoints, shapeProj@data, by="id")
install.packages("tenserflow")
install.packages("tensorflow")
library(tensorflow)
install_tensorflow()
a <- tf$constant(1, dtype=tf$float32, name='a')
b <- tf$constant(1, dtype=tf$float32, name='b')
add <- tf$add(a, b, name='add') # same as a+b
c <- tf$constant(5, dtype=tf$float32, name='c')
mul <- tf$multiply(add, c, name='mul') # same as c*(a+b)
sess <- tf$Session()
print(sess$run(c(a,b,c,add,mul)))
writer <- tf$summary$FileWriter("output",sess$graph)
writer$close()
sess$close()
tensorboard("output")
data_tf <- tf$placeholder(tf$float32,shape(2,2))
size_tf <- tf$placeholder(tf$int32)
data_tf <- tf$placeholder(tf$float32,shape(2,2)) # 2X2 float matrix
size_tf <- tf$placeholder(tf$int32)
seq_tf <- tf$linspace(start=1.0, stop=0.0, num=size_tf+1L)
flipseq_tf <- tf$linspace(start=0.0, stop=1.0, num=size_tf+1L)
mat1_tf <- tf$concat(list(list(seq_tf),list(flipseq_tf)),axis=0L)
mat2_tf <- tf$transpose(mat1_tf)
h1_tf <- tf$matmul(data_tf,mat1_tf)
out_tf <- tf$matmul(mat2_tf,h1_tf)
tf_output <- out_tf
tf_output
devtools::install_github("rstudio/keras")
library("keras")
install_keras()
bookdown:::mathquill()
d <- read.csv(file.choose())
head(d)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
# tm_feature_train <- NA
# if(run.feature.train){
#   tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
#   feat_train <- dat_train$feature
#   label_train <- dat_train$label
# }
#
# save(dat_train, file="../output/feature_train.RData")
load(file="../output/feature_train.RData")
feat_train <- dat_train$feature
label_train <- dat_train$label
source("../lib/train.R")
source("../lib/test.R")
source("../lib/nnet_test.R")
source("../lib/train_neuralnetwork_qiaqia.R")
#install.packages('caret', dependencies = TRUE)
#library(caret)
#run.nnt =T
#if(run.nnt){
#  nnet_train <- train_nnet(feat_train, label_train)
#}
#save(nnet_train, file="../output/nnt_train.RData")
#test_train<-
#run.nnt.test=TRUE
#if(run.nnt.test){
#nnet_test <- nnet_test(nnet_train, test_train)
#}
#save(nnet_test, file="../output/nnet_test.RData")
test_dir <- "../data/test_set/"
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
LR_dir<- test_LR_dir
HR_dir<- test_HR_dir
summary(feat_train)
dim(feat_train)
dim(label_train)
max(label_train)
min(label_train)
imgLRObj <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", 1), ".jpg"))
LR_dir <- "/Users/gabrielbenedict/Google_Drive/docs/UNIS/KU Leuven/Exchange/columbia/Courses/Applied Data Science/Projects/Fall2018-Proj3-Sec1-grp8/data/train_set/LR/"
HR_dir <- "/Users/gabrielbenedict/Google_Drive/docs/UNIS/KU Leuven/Exchange/columbia/Courses/Applied Data Science/Projects/Fall2018-Proj3-Sec1-grp8/data/train_set/HR/"
imgLRObj <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", 1), ".jpg"))
imgHRObj <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", 1), ".jpg"))
imgLR <- as.array(imgLRObj@.Data)
imgHR <- as.array(imgHRObj@.Data)
width <- dim(imgLR)[1]
height <- dim(imgLR)[2]
## step 1. sample n_points from imgLR
set.seed(100)
x <- sample(1:width, n_points, replace = T)
y <- sample(1:height, n_points, replace = T)
n_points=1000
## step 1. sample n_points from imgLR
set.seed(100)
x <- sample(1:width, n_points, replace = T)
y <- sample(1:height, n_points, replace = T)
p <- 1
# define square (don't allow for out of bound subscripts)
square <- imgLR[
(x[p] - 1):as.integer(((x[p] + 1) > width) * width
+ ((x[p] + 1) <= width) * (x[p] + 1)),
(y[p] - 1):as.integer(((y[p] + 1) > height) * height
+ ((y[p] + 1) <= height) * (y[p] + 1)), ]
square
# padding zeros for boundary points
if(dim(square)[1] < 3){
square <- apply(square, c(2, 3), c, 0)
}
if(dim(square)[2] < 3){
# https://stackoverflow.com/questions/27637393/adding-column-or-row-in-3d-array
square <- aperm(apply(square, c(1, 3), c, 0), c(2, 1, 3))
}
vectorized <- c(square)
vectorized <- vectorized - (!vectorized == 0) * c(rep(vectorized[5], 9),
rep(vectorized[14], 9),
rep(vectorized[23], 9))
vectorized <- vectorized[c(-5, -14, -23)] # no central pixel
featMat[(i-1) * n_points + p,,] <- vectorized
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
n_files <- length(list.files(LR_dir))
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
featMat[(i-1) * n_points + p,,] <- vectorized
i <- 1
featMat[(i-1) * n_points + p,,] <- vectorized
featMat[(i-1) * n_points + p,,]
square <- imgHR[(x[p] * 2 - 1):(x[p] * 2),
(y[p] * 2 - 1):(y[p] * 2), ]
square
vectorized <- c(square)
vectorized <- vectorized - (!vectorized == 0) * c(rep(vectorized[5], 9),
rep(vectorized[14], 9),
rep(vectorized[23], 9))
centPixel <- vectorized[c(5, 14, 23)]
centPixel
# define square (don't allow for out of bound subscripts)
square <- imgLR[
(x[p] - 1):as.integer(((x[p] + 1) > width) * width
+ ((x[p] + 1) <= width) * (x[p] + 1)),
(y[p] - 1):as.integer(((y[p] + 1) > height) * height
+ ((y[p] + 1) <= height) * (y[p] + 1)), ]
# padding zeros for boundary points
if(dim(square)[1] < 3){
square <- apply(square, c(2, 3), c, 0)
}
if(dim(square)[2] < 3){
# https://stackoverflow.com/questions/27637393/adding-column-or-row-in-3d-array
square <- aperm(apply(square, c(1, 3), c, 0), c(2, 1, 3))
}
vectorized <- c(square)
vectorized <- vectorized - (!vectorized == 0) * c(rep(vectorized[5], 9),
rep(vectorized[14], 9),
rep(vectorized[23], 9))
centPixel <- vectorized[c(5, 14, 23)]
centPixel
display(imgLRObj)
x[1]
vectorized <- c(square)
vectorized
centPixel <- vectorized[c(5, 14, 23)]
centPixel
square <- imgHR[(x[p] * 2 - 1):(x[p] * 2),
(y[p] * 2 - 1):(y[p] * 2), ]
square
c(square)
c(rep(centPixel[1], 4),
rep(centPixel[2], 4),
rep(centPixel[3], 4))
c(square) - c(rep(centPixel[1], 4),
rep(centPixel[2], 4),
rep(centPixel[3], 4))
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
#install.packages("gbm")
library("gbm")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
# model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
save(dat_train, file="../output/feature_train.RData")
model_best
model_best <- c(2, 10, 0.3)
tm_train <- system.time(fit_train <- train(feat_train, label_train, model_best))
source("../lib/train.R")
source("../lib/test.R")
source("../lib/nnet_test.R")
tm_train <- system.time(fit_train <- train(feat_train, label_train, model_best))
depths <- 2:3
trees <- c(10,20)
bags <- seq(0.3, 0.7, 0.1)
# all combinations
model_values <- expand.grid(depths = depths, trees = trees, bags = bags)
model_values
model_best <- model_values[1,]
model_best
tm_train <- system.time(fit_train <- train(feat_train, label_train, model_best))
save(fit_train, file="../output/fit_train.RData")
str(feat_train)
str(fit_train)
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", 1), ".jpg"))
test_dir <- "../data/test_set/"
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
LR_dir<- test_LR_dir
HR_dir<- test_HR_dir
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", 1), ".jpg"))
getwd()
test_dir <- "../data/test_set/"
getwd()
setwd("/Users/gabrielbenedict/Google_Drive/docs/UNIS/KU Leuven/Exchange/columbia/Courses/Applied Data Science/Projects/Fall2018-Proj3-Sec1-grp8/lib")
test_dir <- "../data/test_set/"
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
LR_dir<- test_LR_dir
HR_dir<- test_HR_dir
HR_dir<- test_HR_dir
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", 1), ".jpg"))
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", 1), ".jpg")
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
rows=dim(imgLR)[1]
cols=dim(imgLR)[2]
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for (d in 1:3) {
padded<- matrix(0,nrow = rows+2,ncol = cols+2)
padded[2:(rows+1),2:(cols+1)]<- imgLR@.Data[,,d]
count<- 0
for (k in 2:(rows+1)) {
for (j in 2:(cols+1)) {
neighbor8<- c(padded[k-1,j-1],padded[k,j-1],padded[k+1,j-1],padded[k-1,j],padded[k+1,j],padded[k-1,j+1],padded[k,j+1],padded[k+1,j+1])
- (c(padded[(k-1):(k+1),(j-1):(j+1)])[-5] !=0) * padded[k,j]
count <- count+1
featMat[count,,d]<- neighbor8
}
}
}
### step 2. apply the modelList over featMat
#predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
modelList <- model_best
### step 2. apply the modelList over featMat
#predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
modelList <- fit_train
### step 2. apply the modelList over featMat
#predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
#predMAT<- test(modelList,featMat,test.nnet =T)  # for neural network
predMAT<- test(modelList,featMat,test.xgboost = T)  # for xgboost
### step 2. apply the modelList over featMat
predMAT <- test(modelList, featMat,test.gbm = T) # for baseline
### step 3. recover high-resolution from predMat and save in HR_dir
predArray<- array(predMAT,c(rows*2,cols*2,3))
predArray
imgLR <- as.array(imgLR@.Data)
dim(imgLR)
vec<- c(rep(rep(c(imgLR)[1:2],c(2,2)),2),rep(rep(c(imgLR)[3:4],c(2,2)),2))
vec
head(imgLR)
dim(imgLR)
diyplay(imgLR)
display(imgLR)
i <- 1
j <- 1
predArray[(i*2-1):i*2, (j*2-1):j*2,]
predArray[(i*2-1):(i*2), (j*2-1):(j*2),]
imgLR[i,j,]
predArray[i*2-1, j*2-1,]
predArray[i*2-1, j*2-1,]
imgLR[i,j,]
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
predicted_image<- Image(predArray,colormode = Color)
display(predicted_image)
for(i in 1:rows){
for(j in 1:cols){
predArray[i*2-1, j*2-1,] <- predArray[i*2-1, j*2-1,] + imgLR[i,j,]
predArray[i*2, j*2-1,] <- predArray[i*2, j*2-1,] + imgLR[i,j,]
predArray[i*2-1, j*2,] <- predArray[i*2-1, j*2,] + imgLR[i,j,]
predArray[i*2, j*2,] <- predArray[i*2, j*2,] + imgLR[i,j,]
}
}
display(imgLR)
display(predicted_image)
